{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = defaultdict(dict)\n",
    "\n",
    "\n",
    "with open(\"together/prompts_long.json\") as f:\n",
    "    json_obj = json.load(f)\n",
    "    for ind, obj in enumerate(json_obj):\n",
    "        prompt = obj[\"question\"]\n",
    "        prompts[prompt][\"question\"] = prompt\n",
    "        prompts[prompt][\"answer\"] = obj[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"da4a68310cb6eb918e9f34d9509695bbccba1585555875aa384ad71fa9d15a84\"\n",
    "import sys\n",
    "sys.path.insert(1, 'api')\n",
    "from togetherclass import TogetherModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n"
     ]
    }
   ],
   "source": [
    "print(len(prompts))\n",
    "PROMPT = \"Answer the following multiple choice question. The first character in the response should be the selected multiple choice letter. Do NOT ouptut the correct answer at the end but instead at the beginning. Question: {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1168 [00:58<32:18,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e0ef7f0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 52/1168 [01:06<26:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e024040 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 57/1168 [01:13<26:31,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d1a97c0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 98/1168 [02:01<24:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e140040 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 109/1168 [02:14<25:47,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e0ef070 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 113/1168 [02:20<26:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e23d700 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 145/1168 [03:00<23:31,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e15b160 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 150/1168 [03:06<23:37,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e199ac0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 157/1168 [03:15<25:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e127ca0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 161/1168 [03:21<26:11,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e2224c0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 173/1168 [03:36<24:33,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e23f5b0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 196/1168 [04:07<23:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e303640 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 213/1168 [04:30<26:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d150700 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 330/1168 [07:08<21:57,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e199ac0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 352/1168 [07:35<18:47,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e15b2e0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 364/1168 [07:47<12:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc672120dc0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 384/1168 [08:20<21:56,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e054610 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 437/1168 [09:29<18:45,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc56c43d340 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 448/1168 [09:45<20:41,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d191ca0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 497/1168 [10:51<14:22,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d135fa0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 510/1168 [11:06<12:57,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d0f2e50 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 519/1168 [11:19<16:46,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d15a940 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 530/1168 [11:30<13:35,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e304bb0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 593/1168 [12:54<13:21,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d166790 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 671/1168 [14:38<07:43,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e15b130 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 707/1168 [15:33<12:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e120af0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 720/1168 [15:50<10:07,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc672180670 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 749/1168 [16:30<12:13,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d1a06d0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 783/1168 [17:13<05:43,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e186bb0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 785/1168 [17:19<10:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d14c580 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 812/1168 [17:52<07:58,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc67212c790 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 816/1168 [17:57<07:26,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e054a00 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 839/1168 [18:28<10:27,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e054640 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 849/1168 [18:39<10:07,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d14c8e0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 853/1168 [18:45<08:49,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e1551c0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 861/1168 [18:54<07:26,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e3003a0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 867/1168 [19:03<07:55,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e2288e0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 881/1168 [19:22<08:15,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc67216db20 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 906/1168 [19:53<06:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e06f820 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 942/1168 [20:39<03:26,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e23dc70 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 944/1168 [20:45<05:49,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d19e3a0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 959/1168 [21:04<04:57,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d10de50 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 971/1168 [21:22<06:18,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68e22bd90 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1010/1168 [22:12<04:51,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d10de80 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1027/1168 [22:31<02:22,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc672120730 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1039/1168 [22:52<04:02,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc6721627c0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1067/1168 [23:33<03:59,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d1304c0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1082/1168 [23:55<02:44,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d105c40 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1104/1168 [24:24<01:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc67214ca60 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1118/1168 [24:39<00:50,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d10d700 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1153/1168 [25:25<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in get_response: RetryError[<Future at 0x7fc68d1279d0 state=finished raised RateLimitError>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1168/1168 [25:46<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "queries = [[PROMPT.format(question=prompts[i][\"question\"])] for i in prompts.keys()]\n",
    "model = TogetherModel(\"Qwen/Qwen1.5-1.8B-Chat\")\n",
    "model.RPI = 10\n",
    "model.MAX_WORKERS = 2\n",
    "model.INTERVAL = 1\n",
    "resp = model.get_responses(queries, {\"temperature\": 0.7, \"top_p\": 0.7})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"together/save_qwen.json\", \"w+\") as f:\n",
    "    json.dump({\"resp\": resp}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D. Transformation\n"
     ]
    }
   ],
   "source": [
    "print(resp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for q, r, p in list(zip(queries, resp, list(prompts.keys()))):\n",
    "    if r == None:\n",
    "        pass\n",
    "        # r = TogetherModel(\"Qwen/Qwen1.5-1.8B-Chat\").get_responses([q], {\"temperature\": 0.7, \"top_p\": 0.7})\n",
    "        # prompts[p][\"base_model\"] = r[0]\n",
    "    else:\n",
    "        prompts[p][\"base_model\"] = r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTHS = [\"short\", \"medium\", \"long\"]\n",
    "for l in LENGTHS:\n",
    "    with open(f\"together/responses_{l}.json\") as f:\n",
    "        json_obj = json.load(f)\n",
    "        for obj in json_obj:\n",
    "            prompts[obj[\"prompt\"]][f\"response_{l}\"] = obj[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-1.8B-Chat\")\n",
    "\n",
    "with open(\"together/dataset_length.jsonl\", \"w+\") as f:\n",
    "    for obj in prompts.values():\n",
    "        human_prompt = PROMPT.format(question=obj['question'])\n",
    "        obj[\"prompt\"] = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": human_prompt}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        f.write(json.dumps(obj)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in prompts.values():\n",
    "    assert set(obj.keys()) == {\"response_short\", \"response_medium\", \"response_long\", \"base_model\", \"question\", \"answer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n"
     ]
    }
   ],
   "source": [
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a short introduction to large language model.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-1.8B-Chat\")\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
